{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Febilid/Pem_Mesin/blob/main/Week_10_Praktikum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Job Sheet 10: Recurrent Neural Network (RNN)\n",
        "# Nama: Febiola lidya Sianturi\n",
        "# NIM: 2241720229\n",
        "# Kelas: TI-3H\n",
        "# No: 10"
      ],
      "metadata": {
        "id": "7Nf2ipD84XHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Praktikum 1 RNN untuk Analisis Sentimen\n",
        "# Setup\n",
        "Impor matplotlib dan buat fungsi pembantu untuk memplot grafik:"
      ],
      "metadata": {
        "id": "w7hLTSqg5Lu2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uGGaJzjO3I27"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])"
      ],
      "metadata": {
        "id": "8yymOaJl5f2J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup input pipeline"
      ],
      "metadata": {
        "id": "kX8c8-2O6VSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
        "                          as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "train_dataset.element_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsKtaaqa60je",
        "outputId": "0b38e023-d52d-4e0e-c27d-a78006528435"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\n",
            "Dataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('text: ', example.numpy())\n",
        "  print('label: ', label.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EmbMlxxM3hs",
        "outputId": "5d8f4942-3559-40ad-e1ff-dc002f15311b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
            "label:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "for example, label in train_dataset.take(1):\n",
        "  print('texts: ', example.numpy()[:3])\n",
        "  print()\n",
        "  print('labels: ', label.numpy()[:3])"
      ],
      "metadata": {
        "id": "fyDn-rhLOSJH",
        "outputId": "fd7aec44-7103-42cc-b282-9c3e44a13108",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texts:  [b'Conrad Hall went out with a bang. The great film photographer finished his illustrious career with this movie before passing on. He did himself proud as this is one of the best-looking crime films you\\'ll ever see.<br /><br />Of course, the acting ain\\'t bad when you have Tom Hanks and Paul Newman playing the leads! The amount of action in here is just right, too: not too much; not too little.<br /><br />None of the characters in here, frankly, are \"good guys\" as Hanks is a professional hit-man for town boss Newman. Hanks\\' only redeeming quality is not wanting his young son to wind up a killer like him, although he does teach him how to be the getaway man in robberies! Huh?<br /><br />As good as the acting is and as interesting as the story is, the real star of this film is cinematographer Hall, who paints scene after beautiful scene with his lens. His work is just awesome.'\n",
            " b'Reasons to watch the movie:<br /><br />1) Bo Derek at 16 looks good and occasionally gets naked. She does a pretty good job playing an immature, insecure 16 year old beauty, in fact<br /><br />2) Many shots of a pretty Greek island<br /><br />But:<br /><br />1) Peter Hooten turns in the worst performance by an actor since Brutus played Caeser\\'s friend in \"Roman Senate Proceedings of March 15.\" He delivers each and every line in a delightful baritone bellow. Turn down the volume whenever he speaks. Preferably all the way down<br /><br />2) Bo\\'s fantasies are sadly tame, especially by today\\'s standards. A few turns in the bath and as a fully clothed model<br /><br />3) The plot is skimpier than Bo\\'s costumes'\n",
            " b'It\\'s utterly pointless to rate this film. It\\'s as if you would condemn (or praise) the newly born for his future life. Instead look at it as a powerful meditation at what could have been and what has been in the past 100+years. One hundred and eight years of the cinematograpy: what has become of the babe? I like to contemplate on what would have (creatively) happen if Europe wasn\\'t interrupted (devastated) twice by the great wars of the XXth century. On her ruins the bogus neon castle of the non-creative and reactionary circus named Hollywood erected itself. Before 1914 French, Italian and Scandinavian cinemas were leading the way both financially and of course creatively. French film in particular was already threading some very original and creative pathways that could have (if not interrupted) possibly altered the medium history in some unimaginable ways. One wonders what the film history would look like today if it wasn\\'t stultified and choked by the mercantile and cheap political agenda of the Hollywood\\'s 80+ years of, what Chekhov might define as the reek of greed and harlotry... Be it as it might, please at least become aware of La Sortie as the key (or at least one of them) to the \"Kingdom\". Thus the birthplace of Cinema : Lumiere Brothers Factory, Lyon, France The date: March 19th 1895 (there\\'s also a replica reel shoot in the Summer of 1895 so if you notice Summer lights and the workers\\' lighter clothing: that was the version shown to THE VERY FIRST PEOPLE WHO EVER SAW THE MOVING IMAGES. *Louis Lumiere: creative ideas, cinematography, direction it was all Louis\\' own domain because Auguste took care of the rest (money). *First film reels were all fifty seconds long: the camera(=le Cinematograph) & the cameramen (le cinematographer) having only paltry fifty seconds to make things happen! *Apparently Le Institute Lumiere has managed to preserve around 1500 of these first films executed mostly by an industrious brigade of Loumiere travelling cinematographers criss-crossing the globe. ***So, all the stars in starry heavens and a minute of silence for perhaps the most magical invention in Human history (so far).']\n",
            "\n",
            "labels:  [1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Buat Teks Encoder"
      ],
      "metadata": {
        "id": "vuvCHJqiOjpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 1000\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))"
      ],
      "metadata": {
        "id": "lT7YPrQhOk3f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]"
      ],
      "metadata": {
        "id": "S4dhiRSnO23T",
        "outputId": "546cbf87-10d0-48d3-be38-c675e418028a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
              "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but'],\n",
              "      dtype='<U14')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_example = encoder(example)[:3].numpy()\n",
        "encoded_example"
      ],
      "metadata": {
        "id": "azfq9kOYO3-W",
        "outputId": "c119906f-ed6e-4bfc-89ab-5ec06d0300a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1,   1, 418, ...,   0,   0,   0],\n",
              "       [  1,   6, 104, ...,   0,   0,   0],\n",
              "       [ 30,   1,   1, ...,   0,   0,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n in range(3):\n",
        "  print(\"Original: \", example[n].numpy())\n",
        "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
        "  print()"
      ],
      "metadata": {
        "id": "2VM4tXizO6Dy",
        "outputId": "21afe3bc-4084-4956-c4cc-96c6aebffdc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  b'Conrad Hall went out with a bang. The great film photographer finished his illustrious career with this movie before passing on. He did himself proud as this is one of the best-looking crime films you\\'ll ever see.<br /><br />Of course, the acting ain\\'t bad when you have Tom Hanks and Paul Newman playing the leads! The amount of action in here is just right, too: not too much; not too little.<br /><br />None of the characters in here, frankly, are \"good guys\" as Hanks is a professional hit-man for town boss Newman. Hanks\\' only redeeming quality is not wanting his young son to wind up a killer like him, although he does teach him how to be the getaway man in robberies! Huh?<br /><br />As good as the acting is and as interesting as the story is, the real star of this film is cinematographer Hall, who paints scene after beautiful scene with his lens. His work is just awesome.'\n",
            "Round-trip:  [UNK] [UNK] went out with a [UNK] the great film [UNK] [UNK] his [UNK] career with this movie before [UNK] on he did himself [UNK] as this is one of the [UNK] crime films youll ever [UNK] br of course the acting [UNK] bad when you have tom [UNK] and paul [UNK] playing the leads the [UNK] of action in here is just right too not too much not too [UNK] br none of the characters in here [UNK] are good guys as [UNK] is a [UNK] [UNK] for town [UNK] [UNK] [UNK] only [UNK] quality is not [UNK] his young son to [UNK] up a killer like him although he does [UNK] him how to be the [UNK] man in [UNK] [UNK] br as good as the acting is and as interesting as the story is the real star of this film is [UNK] [UNK] who [UNK] scene after beautiful scene with his [UNK] his work is just [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
            "\n",
            "Original:  b'Reasons to watch the movie:<br /><br />1) Bo Derek at 16 looks good and occasionally gets naked. She does a pretty good job playing an immature, insecure 16 year old beauty, in fact<br /><br />2) Many shots of a pretty Greek island<br /><br />But:<br /><br />1) Peter Hooten turns in the worst performance by an actor since Brutus played Caeser\\'s friend in \"Roman Senate Proceedings of March 15.\" He delivers each and every line in a delightful baritone bellow. Turn down the volume whenever he speaks. Preferably all the way down<br /><br />2) Bo\\'s fantasies are sadly tame, especially by today\\'s standards. A few turns in the bath and as a fully clothed model<br /><br />3) The plot is skimpier than Bo\\'s costumes'\n",
            "Round-trip:  [UNK] to watch the moviebr br 1 [UNK] [UNK] at [UNK] looks good and [UNK] gets [UNK] she does a pretty good job playing an [UNK] [UNK] [UNK] year old beauty in [UNK] br 2 many shots of a pretty [UNK] [UNK] br [UNK] br 1 peter [UNK] turns in the worst performance by an actor since [UNK] played [UNK] friend in [UNK] [UNK] [UNK] of [UNK] [UNK] he [UNK] each and every line in a [UNK] [UNK] [UNK] turn down the [UNK] [UNK] he [UNK] [UNK] all the way [UNK] br 2 [UNK] [UNK] are [UNK] [UNK] especially by [UNK] [UNK] a few turns in the [UNK] and as a [UNK] [UNK] [UNK] br 3 the plot is [UNK] than [UNK] [UNK]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
            "\n",
            "Original:  b'It\\'s utterly pointless to rate this film. It\\'s as if you would condemn (or praise) the newly born for his future life. Instead look at it as a powerful meditation at what could have been and what has been in the past 100+years. One hundred and eight years of the cinematograpy: what has become of the babe? I like to contemplate on what would have (creatively) happen if Europe wasn\\'t interrupted (devastated) twice by the great wars of the XXth century. On her ruins the bogus neon castle of the non-creative and reactionary circus named Hollywood erected itself. Before 1914 French, Italian and Scandinavian cinemas were leading the way both financially and of course creatively. French film in particular was already threading some very original and creative pathways that could have (if not interrupted) possibly altered the medium history in some unimaginable ways. One wonders what the film history would look like today if it wasn\\'t stultified and choked by the mercantile and cheap political agenda of the Hollywood\\'s 80+ years of, what Chekhov might define as the reek of greed and harlotry... Be it as it might, please at least become aware of La Sortie as the key (or at least one of them) to the \"Kingdom\". Thus the birthplace of Cinema : Lumiere Brothers Factory, Lyon, France The date: March 19th 1895 (there\\'s also a replica reel shoot in the Summer of 1895 so if you notice Summer lights and the workers\\' lighter clothing: that was the version shown to THE VERY FIRST PEOPLE WHO EVER SAW THE MOVING IMAGES. *Louis Lumiere: creative ideas, cinematography, direction it was all Louis\\' own domain because Auguste took care of the rest (money). *First film reels were all fifty seconds long: the camera(=le Cinematograph) & the cameramen (le cinematographer) having only paltry fifty seconds to make things happen! *Apparently Le Institute Lumiere has managed to preserve around 1500 of these first films executed mostly by an industrious brigade of Loumiere travelling cinematographers criss-crossing the globe. ***So, all the stars in starry heavens and a minute of silence for perhaps the most magical invention in Human history (so far).'\n",
            "Round-trip:  its [UNK] [UNK] to [UNK] this film its as if you would [UNK] or [UNK] the [UNK] [UNK] for his future life instead look at it as a powerful [UNK] at what could have been and what has been in the past [UNK] one [UNK] and [UNK] years of the [UNK] what has become of the [UNK] i like to [UNK] on what would have [UNK] happen if [UNK] wasnt [UNK] [UNK] [UNK] by the great [UNK] of the [UNK] [UNK] on her [UNK] the [UNK] [UNK] [UNK] of the [UNK] and [UNK] [UNK] named hollywood [UNK] itself before [UNK] french [UNK] and [UNK] [UNK] were leading the way both [UNK] and of course [UNK] french film in particular was already [UNK] some very original and [UNK] [UNK] that could have if not [UNK] possibly [UNK] the [UNK] history in some [UNK] ways one [UNK] what the film history would look like today if it wasnt [UNK] and [UNK] by the [UNK] and cheap political [UNK] of the [UNK] [UNK] years of what [UNK] might [UNK] as the [UNK] of [UNK] and [UNK] be it as it might please at least become [UNK] of la [UNK] as the [UNK] or at least one of them to the [UNK] [UNK] the [UNK] of cinema [UNK] brothers [UNK] [UNK] [UNK] the [UNK] [UNK] [UNK] [UNK] theres also a [UNK] [UNK] [UNK] in the [UNK] of [UNK] so if you [UNK] [UNK] [UNK] and the [UNK] [UNK] [UNK] that was the version shown to the very first people who ever saw the moving [UNK] [UNK] [UNK] [UNK] ideas cinematography direction it was all [UNK] own [UNK] because [UNK] took care of the rest money first film [UNK] were all [UNK] [UNK] long the [UNK] [UNK] the [UNK] [UNK] [UNK] having only [UNK] [UNK] [UNK] to make things happen apparently [UNK] [UNK] [UNK] has [UNK] to [UNK] around [UNK] of these first films [UNK] mostly by an [UNK] [UNK] of [UNK] [UNK] [UNK] [UNK] the [UNK] so all the stars in [UNK] [UNK] and a minute of [UNK] for perhaps the most [UNK] [UNK] in human history so far                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Buat Model"
      ],
      "metadata": {
        "id": "v818-P_KO9q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "1-_6dzCTO_Cw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([layer.supports_masking for layer in model.layers])"
      ],
      "metadata": {
        "id": "ZWVNQFhAPCsA",
        "outputId": "0f91be9e-316b-4905-8db2-fe99e34ff45a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False, True, True, True, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Definisikan teks sampel\n",
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "\n",
        "# Tokenisasi teks menggunakan tokenizer\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts([sample_text])\n",
        "tokenized_sequence = tokenizer.texts_to"
      ],
      "metadata": {
        "id": "qHVNRKcLPFhb",
        "outputId": "402a50ff-f519-4a3b-e0c0-168be98d4571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Tokenizer' object has no attribute 'texts_to'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5fd55b27e4c1>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtokenized_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tokenizer' object has no attribute 'texts_to'"
          ]
        }
      ]
    }
  ]
}